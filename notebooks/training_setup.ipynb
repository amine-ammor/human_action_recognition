{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78a0af5-560c-4ad9-99da-4e3a90ea393f",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "truncate = 10\n",
    "location = '/root/.cache/keypoints'\n",
    "clear_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2769dfb-f116-4ed2-8e06-e3782a8a7abd",
   "metadata": {
    "tags": [
     "dataset"
    ]
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "from joblib import Memory\n",
    "memory = Memory(location,verbose=0)\n",
    "if clear_cache:\n",
    "    memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "666677ea-c5ee-4f80-8379-85a0492da083",
   "metadata": {
    "tags": [
     "dataset"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from functools import cached_property\n",
    "from collections import OrderedDict\n",
    "from itertools import islice\n",
    "\n",
    "import keypoints_io\n",
    "folder_video_keypoints = \"../data/keypoints/as_arrays\" \n",
    "folder_video_keypoints = str(Path(folder_video_keypoints).resolve())\n",
    "# with respect to the notebook's directory, all the notebooks are launched with respect to their folder's location\n",
    "# using papermill or ploomber engine\n",
    "\n",
    "def uniform_padding(array,max_shape,value):\n",
    "    dim = len(array.shape) # of set of the arrays\n",
    "    padding_width = ((0,max_shape-array.shape[0]),*[(0,0) for _ in range(dim-1)])\n",
    "    new_array = np.pad(array,padding_width,constant_values=value)\n",
    "    return new_array\n",
    "        \n",
    "    \n",
    "@memory.cache\n",
    "def read_and_filter_keypoints(path_file,with_frame_padding,default_shape=(17,2),max_number_of_frames=None):\n",
    "    if with_frame_padding:\n",
    "        assert isinstance(max_number_of_frames,int),\"a number of maximum frames must be provided\"\n",
    "        with_frame_padding = False\n",
    "        keypoints,is_frame_present = read_and_filter_keypoints(path_file,with_frame_padding,default_shape,\n",
    "                                                              max_number_of_frames)\n",
    "        assert len(keypoints)<=max_number_of_frames\n",
    "        assert len(is_frame_present)<=max_number_of_frames\n",
    "        \n",
    "        keypoints = uniform_padding(keypoints,max_number_of_frames,np.nan)\n",
    "        is_frame_present = uniform_padding(is_frame_present,max_number_of_frames,False)\n",
    "    else:\n",
    "        keypoints,scores = keypoints_io.load(path_file)\n",
    "        keypoints = [keypoints_frames[np.argmax(scores_frames)] if len(scores_frames)>0 else None for (keypoints_frames,scores_frames) in zip(keypoints,scores)]\n",
    "\n",
    "        is_frame_present = np.array([el is not None for el in keypoints])\n",
    "        keypoints = np.array([el if keep else np.nan*np.ones(default_shape)  for el,keep in zip(keypoints,is_frame_present)])\n",
    "        keypoints = keypoints.astype(\"float32\")\n",
    "    keypoints = np.nan_to_num(keypoints)\n",
    "    return keypoints,is_frame_present\n",
    "\n",
    "\n",
    "class VideoKeyPointDataset(Dataset):\n",
    "    def __init__(self,folder_video_keypoints,with_frame_padding=True,truncate=None):\n",
    "        self.folder_video_keypoints = folder_video_keypoints\n",
    "        self.with_frame_padding = with_frame_padding\n",
    "        self.video_keypoints_field_paths = list(islice(Path(self.folder_video_keypoints).rglob(\"*.npz\"),truncate))\n",
    "    @cached_property\n",
    "    def number_of_frames(self):\n",
    "        assert not(self.with_frame_padding),\"can't get the exact number of frames if padding is activated\"\n",
    "        res = {i:len(self.__getitem__(i)[\"kpts\"]) for i in range(len(self))}\n",
    "        return res\n",
    "    \n",
    "    @cached_property\n",
    "    def max_number_of_frames(self):\n",
    "        res = max(self.number_of_frames.values())\n",
    "        return res\n",
    "\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        outputs = OrderedDict()\n",
    "        if self.with_frame_padding:\n",
    "            assert \"max_number_of_frames\" in self.__dict__,\"\"\"\n",
    "            max_number_of_frames should be computed at least once,with self.with_frame_padding\n",
    "            set to False before using padding \n",
    "            \"\"\"\n",
    "            kpts,is_detection_present = read_and_filter_keypoints(self.video_keypoints_field_paths[i],\n",
    "                                                          with_frame_padding=self.with_frame_padding,\n",
    "                                                          max_number_of_frames=self.max_number_of_frames)\n",
    "            outputs[\"number_of_frames\"]=self.number_of_frames[i]\n",
    "        else:\n",
    "            kpts,is_detection_present = read_and_filter_keypoints(self.video_keypoints_field_paths[i],\n",
    "                                                          with_frame_padding=self.with_frame_padding,\n",
    "                                                              max_number_of_frames=None)\n",
    "        outputs.update(kpts=kpts,\n",
    "                      is_detection_present=is_detection_present)\n",
    "        return outputs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.video_keypoints_field_paths)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "540197f8-32de-45e6-b7f1-eb837916a06e",
   "metadata": {
    "tags": [
     "dataset"
    ]
   },
   "outputs": [],
   "source": [
    "video_kpt_dataset = VideoKeyPointDataset(folder_video_keypoints,with_frame_padding=False,truncate=truncate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92a9e769-4a04-4ecc-b9c6-cc26e155e76e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "if truncate is not None:\n",
    "    assert len(video_kpt_dataset) == min(truncate,len(video_kpt_dataset.folder_video_keypoints))\n",
    "print(len(video_kpt_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b368347e-35ba-473f-aafb-4ab2918caf69",
   "metadata": {
    "tags": [
     "notebook_call"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing cell: 8: 100%|██████████████████████████| 9/9 [00:01<00:00,  4.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# fill the cache and print informations about caching in other notebook\n",
    "from ploomber_engine.ipython import PloomberClient\n",
    "\n",
    "path_cache_setup = \"./performance_tests/caching_tests_and_metrics.ipynb\"\n",
    "path_cache_setup = str(Path(path_cache_setup).resolve())\n",
    "\n",
    "client = PloomberClient.from_path(path_cache_setup,remove_tagged_cells=\"notebook_call\")\n",
    "namespace = client.get_namespace(dict(video_kpt_dataset=video_kpt_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf2730c1-2e23-4217-ac3b-6d834882c930",
   "metadata": {
    "tags": [
     "dataloader"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def collatefn(batch):\n",
    "    batch = {k: [dic[k] for dic in batch] for k in batch[0]}\n",
    "    nb_frames,kpts,is_detection_present = batch.values()\n",
    "    max_nb_frames = max(nb_frames) \n",
    "    # we compute the maximum over the batch for some extra computation savings\n",
    "    kpts = torch.tensor(kpts)\n",
    "    kpts = kpts.reshape(kpts.shape[0],kpts.shape[1],-1)\n",
    "    is_detection_present = torch.tensor(is_detection_present)\n",
    "    \n",
    "    kpts = kpts[:,:max_nb_frames]\n",
    "    is_detection_present = is_detection_present[:,:max_nb_frames]\n",
    "    #nb_frames = np.array(nb_frames)\n",
    "    return kpts,is_detection_present\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "video_dataloader = DataLoader(video_kpt_dataset,shuffle=True,collate_fn=collatefn,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e09d35e2-415e-438c-bd21-d0d3aa81a160",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11213/652576668.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  kpts = torch.tensor(kpts)\n",
      "/tmp/ipykernel_11213/652576668.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  is_detection_present = torch.tensor(is_detection_present)\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    res = next(iter(video_dataloader))\n",
    "    res[0].shape,res[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73d853a3-7210-4750-ab28-f38bd5cc1f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(video_dataloader.sampler) == torch.utils.data.sampler.RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593a3fc-1638-4462-9e6d-a36504bd2f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sanity check test\n",
    "#res[0][0].numpy()\n",
    "#video_kpt_dataset[0][0]#res[0][0].numpy()\n",
    "#video_kpt_dataset[0][0]#res[0][0].numpy()\n",
    "#video_kpt_dataset[0][0]\n",
    "unshuffled = False\n",
    "if unshuffled:\n",
    "    loader_iter = iter(d_loader)\n",
    "    res = next(loader_iter)\n",
    "    assert np.all(res[0][0][6].numpy() == video_kpt_dataset[0][0][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c846e-1576-4adf-ab90-7d9d29f85625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
